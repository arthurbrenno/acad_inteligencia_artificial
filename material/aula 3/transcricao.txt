Mesma configuração do perceptor, só que ele usou uma rede de neurônios, não tem só mais um neurônio, tem uma rede de dedos. O que acontece, eu tenho a feed-forward e a propagação, o que vocês pensam? Eu? Não, o Raul. O que é isso, filho? Eu não disse nada. Não, eu sei não, é isso, pulado. Você nunca faz nada. Vai canonizar o seu Raul. Está calmo? Não, não está calmo? O pessoal está exigindo até o final da manhã. Está exigindo? Então é você que vai dar, rapaz. Vamos lá. O moleque que golpeou ontem, ele resolveu fazer uma xadrez comigo, vamos fazer uma xadrez. Vamos lá. Foi uma partida só, só. Fiquei até o meio da manhã desgravado. Quando eu descer é mais uma, mais uma, mais uma. Mas você deixou de ganhar nada. Você também ganhou isso, né? Não, então, se você ganhasse, parava, né? Vamos lá, pessoal, vamos lá. Bom, o Zé Bombinha chegou hoje. Você não palestra, palestra nem. Eu não sou de palestra não, hein? Eu não sou de palestra não, sei lá. O Zé vai ter mexido muito no meu bolso. Ele tem o olho explosivo aí. Vamos lá. Vai que a palestra... Deixa a palestra pra lá. No Hava não tem nada nosso, no Hava não tem nada. Se não tem no Hava, não tem nada. Então, você não estaria falando pra gente no Hava pra ir pra palestra, né? É, vamos lá. Pessoal, vamos prestar atenção aqui. Por favor, prestem atenção. Que não enrola depois. Eu convencionei da seguinte forma. Quando eu estou trabalhando com neurônios, que eu tenho A, B, C, D, E, F, G, H e F. O que eu vou convencionar na minha cabeça? Quando eu vou trabalhar com a camada de neurônios, tudo que é coluna é neurônio. E tudo que é linha é a entrada deles, correto? Se eu tenho dois neurônios aqui, vai ficar assim. A, B, C, D, E, F. Correto ou não? Pois é, então a gente vai olhar uma matriz. É, cansado de falar de vocês. Certo? Se tivesse aqui seis neurônios, teria seis colunas. Três entradas, três linhas. Beleza? Beleza? Cansado, vamos lá. Camada de saio. G, H, I. Então eu tenho um neurônio com três entradas. Agora é só a vida. Seu neurônio é matriz e neurônio, certo? Estão lendo aqui, ó. Dois neurônios, três entradas. Um neurônio, três entradas. Beleza? Só que seria as bolinhas. Então o número de entradas aqui eu não tenho. Eu tenho uma, duas, três entradas. O neurônio seria as bolinhas. Isso. Beleza? Então, lógico, bota isso na cabeça. Segunda coisa. O dente, que desenvolveu um algoritmo na cabeça. O que é a condição da minha picadinha? Como eu estou deslocando de uma camada para outra, eu tenho um sistema, eu tenho um período de tempo. Eu estou no processo disso. O outro é só o neurônio. Eu tenho que pegar aquilo aqui para o lado de cá. Esse neurônio aqui, especificamente, o algoritmo de Heteronarquia, ele só funciona se a derivada da função for o quê? Diferente de? Zero. O que eu aprendi na aula passada, que é o degrau. Dá certo aqui? Não. Por quê? Degrau é o valor o quê? O vitálio. Ele não vai de zero a um? Se a derivada de um é zero, a derivada de zero é zero. Isso não funciona em uma rede multicamada. Esquece. Esse cara não funciona. Então, o que acontece? Eu vi que a função mais básica para esse tipo de rede é chamada de função logística. Essa daqui. Essa é a função mais básica da rede. Para esse tipo de rede. Então, tem que fazer a derivada desse cara e tal? Tem. Vou fazer rapidinho aqui. A derivada desse cara vai dar o quê? A derivada da parte superior, que é zero, vezes a parte inferior, menos o quê? A derivada desse aqui, não é? Vai dar mais e de menos net, vezes um, vai dar aqui mesmo, dividido pelo quê? Pelo denominador elevado ao quadrado. Aqui vai dar a série de obrigada, e vai ficar o quê? E de menos net, dividido por um mais e de menos net, elevado ao quadrado. Aí, o que acontece? O que vamos substituir por distória aqui? O quê? O distória. Entendeu? Foi? Então, vou usar a ideia dele aqui. O que a gente vai fazer? Vai fazer um arranjo. Se eu colocar mais um e menos um em uma função, não um, certo? Então, fica assim. E mais um, um mais e de menos net, certo? Dividido por um mais e de menos net, elevado ao quadrado, menos um sobre um mais e de menos net, elevado ao quadrado. Deixa o mais para cá e o menos para lá. Você compara o que eu corto aqui e aqui? E respeita assim, um sobre um mais e de menos net, menos um sobre um mais e de menos net, elevado ao quadrado. O que eu vou olhar? Isso aqui, não é igual a esse aqui? Posso escrever assim? Isso? Essa é a derivada dessa função. O que a gente vai usar vai ser essa formula aqui. A derivada da função é ela mesma, o resultado dela, multiplicado por um menos ela mesma. Beleza? Por que você faz isso? Se eu não usasse essa equação aqui, se eu nascesse isso aqui, já não resolvia? Resolvia. Só que se eu fazer isso, eu gasto processamento. Por que? Eu já tenho esse resultado aqui. Então, o que eu vou fazer? Vou pegar o resultado, vou fazer um menos o resultado, multiplicado pelo resultado. Eu já tenho o resultado pronto guardado na memória. Eu não preciso vir aqui e fazer essa conta para calcular. Por isso, eu sempre faço, pessoal, eu faço esse ajuste de sempre tentar fechar com a mesma função. Todo mundo que mexe com essa parte geral faz isso. Por que? Para economizar processamento. O motivo é esse. Por exemplo, a matemática também faz processamento. Faz economizar processamento? Faz. Tá? Beleza. Futuramente, se você for mexer com esse movimento de IA, e ele aplicar mesmo, o crescimento, usar a coisa pronta, você tem que fazer IA. Às vezes, não, cara. É uma coisa tão específica que o matemático não faz também, não. Sistemas, eu não sei falar tanto, mas engenharia tem uma diferença absurda. Quando o engenheiro dá aula de matemática para o engenheiro, quando o professor de matemática fala para o engenheiro, o jeito que o engenheiro der a matemática é diferente do jeito que o professor de matemática fala. É diferente. Vamos lá. Então, vamos analisar isso aqui agora. Já tem esse cara. Professor, qual é a função de treinamento? Como é que eu vou fazer esse neurônio aprender isso? O que que acontece? Eu vou pegar a minha variação do meu peso neural. Vai ser o quê? A taxa de aprendizagem, é isso? Vezes a derivada do eu, meu quadrado do meu, que a gente fez na aula passada, pelo peso, multiplicado por quê agora? Pela derivada da minha função de ativação e função de net. Que eu já tenho aqui. Agora a derivada entra. Certo? Se eu for fazer isso aqui, vamos na aula passada, fazer isso tudo, o que que eu faço? Vai fazer o quê? Eu vou fechar a equação assim. Vai ficar a taxa de aprendizagem, isso aí. O D, que é o erro, não é isso? Vamos ver se acontece. O taxe menos a net, lembra? Vezes quem? Vezes a derivada da função, que é essa. Vezes quem? A entrada do neurônio, certo? Se eu pego esse cara, é o valor final mais o valor inicial, então fica W, vai ser igual, vai ser igual a W inicial mais a taxa, o tarte menos a net, a função de ativação X, vai aprender? Então, com o percepto multicamada NC, a função logística de ativação, a minha função de aprendizagem do neurônio vai ser essa. Por exemplo, mudou o erro quadrático, vamos usar o quadrático médio, aí vai mudar isso aqui. Se eu mudar qualquer coisa, meu erro vai ser esse erro. Podia fazer na prova, determina a função de, não posso fazer isso aqui, determina a função de treinamento do neurônio para um erro exponential, então, tangente e percórdia de ativação. Esse cara aqui vai o que? Se for fechado, vai ter 25% de chance. Vou copiar aqui em seguida também. W, W0, mais taxa, tarte menos a net, vezes a derivada da função de ativação X, N, correto? Uma alma saiu aqui. Vamos lá. Como é que vai funcionar isso aqui agora? Como é que eu vou montar o logaritmo com o feed-for-array e o back-propagation? É o seguinte, vamos começar o processo de feed-for-array, vou jogar lá, vai ser assim, Y, que vai sair aqui, nesses caras, o que vai ser? Vai ser a entrada, N-1, X1 e X2, correto? Vezes quem? A, B, C, D, E, F, não é isso? Então, esse vez esse, mais esse vez esse, mais esse vez esse, vai dar o resultado, então Y1, vou chamar assim, esse vez esse, mais esse vez esse, mais esse vez esse, vai dar Y2. Então, a somatória aqui está pronta, e tem que passar pela função de ativação, correto? Os dois vão passar pela função de ativação, eu vou ter aqui, Y1 e Y2', certo? Então, passou pela função de ativação. Vai ser um valor, que vai passar por essa função, vai dar outros valores, certo? Porque essa função de ativação, ela faz o que? Ela faz um variável de 0 a 1. Certo? Aí, o que eu faço agora? Quando sair esse resultado, eu adiciono esse vaiz aqui, então eu tenho Y1 e Y2. Aí, vai dar o quê? Vai ser, G, H e I. Então, vai ser esse vez esse, esse vez esse, esse vez esse, vai dar o quê? YS, saída, passa pela função de ativação, YS' Então, isso eu fiz o que eu fiz? Apliquei o sinal da rede neural, ele foi propagado, e saiu lá o YS' no final. Certo? Então, um vai sair do N cada outro? Não. Então, pelo menos um H, já achei que ia sair desse um e ia sair do outro. Então, sai outro. O Y1 não é igual a H e o Y. Aqui não é igual? É. Ele não tinha que dizer, não. Esse vez esse, mais esse vez esse, mais esse vez esse. Esse vez esse, mais esse vez esse, mais esse, mais esse. São. Tá? Saiu o H. Beleza. Acabou a propagação. Então, o que eu tenho que fazer? O B é que procura mesmo. Eu tenho que jogar essa informação, o que eu vou achar de erro, lá atrás. Como é que eu vou fazer? Lembra da aula passada? O que é o delta? O delta tinha lá. É o tags que eu quero, menos o YS' Eu acho o meu? Eu. Meu D0, o que que vai ser? Porque o D0, pessoal, esse D que eu achei esse erro, ele vai corrigir a camada escondida, essa camada aqui. Ele vai corrigir quem? O G, o H e o Y. Quem vai corrigir o de trás aqui? Não pode ser o D. Por quê? Tem a conexão do neurônio com o outro. Então, vai ser D vezes o Y e D vezes o H. Então, o D0 vai ser o quê? Vai ser o valor do D multiplicado pelo quê? Pelo H e Y. Então, eu tenho D0. Então, esse D0 vai dar o quê? D1, né? D2, certo? Essa multiplicação aí. Ou BH. Esse D0 que vai corrigir quem? O DH vai corrigir primeiro o neurônio e o DH aí vai corrigir o segundo neurônio. Beleza? Como vai ficar então? Vamos fazer a correção da primeira camada lá. Como é que vai ficar? Porque o WD de treinamento, o quê vai ser? Vai ser a taxa, correto? O D do neurônio. O D aqui é o erro. A derivada que é o quê? YS 1 menos YS. Esse quem? Pesa para o pessoal aqui. Menos 1, H e Y. Beleza ou não? Erro. Entrada é menos 1? Ah, tem erro, pessoal. Ficou errado. Aqui é Y, né? Y menos 1, Y menos 2. Erro. Certo? São as entradas. Isso aqui vai gerar 3 números e você vai pegar o W seu com o W antigo e somar com esse WD. Você faz o ajuste da camada de saída. E a camada intermediária, como é que ela vai ficar? Assim, ó. WED, né? Que WSD, né? É assim. Então, o WED, o quê que vai ser o WED? Mesma coisa, só que tem que fazer uma jogadinha aqui de matriz, tá? Vou colocar aqui já as entradas. Aqui é a entrada. Menos 1, X1 e X2, né? Esse que é N. Bicha, tá nervosa? N, TH, D, Y, elevado das, das duas derivadas, com derivadas no índice com 1, derivadas no índice com 2, e soma. Por que que você fez isso? Por exemplo, ó. Aqui você concorda que isso é ponto de multiplicação, tá? Por quê? Quando é ponto de multiplicação faço isso, ó. Isso vezes isso, e isso vezes isso, tá? Então, vai ter dois números de resultado, correto? Eu tenho uma linha e duas colunas. Aqui eu tenho uma coluna e três linhas, correto? Então, aqui é 3 e 1, e aqui é 1 e 2, correto? Uma espécie de matriz, né, pessoal? Eu posso multiplicar por quê? Por que que eu joguei aqui pra frente? Por que que se embola esse carinho com esse, tá vendo disso? Aqui vai me dar quantos números? Vai me dar 6, ó, é isso? Vai me dar 6, ó. Dá 1, 2, 3, 4, 5, 6. Vai me dar 6. E vai ser justamente pra corrigir esses 6 aqui, ó. Certo? Com o resultado encontrado eu faço a mesma coisa, ó. W e, W é igual a W e, mais W e e. Acabou o processo. Realizei a correção de peso. Troque a amostra, troque as entradas, faça a propagação toda de novo, cai aqui, faz a aprendizagem e volta. Faz até acabar todo o processo, eu vou demorar pra aprender, na marca. Legal? Ó, vamos fazer um programinha aí. Vamos ver que é bem sossegado. Vamos lá, colega. Dá pra acompanhar até o raciocínio, não. Dá pra acompanhar até o raciocínio, não. Vou capturar o senhor. Tem uma dica de curso aí pra nós olhar em casa também. Uma dica de curso pra nós olhar em casa. Uma dica de curso pra olhar em casa também. Curso assim não acha, cara. Só se for na UFA, aí você vai achar. Curso bom, amizade, sexo, comida. Vem cá, vai lá. Na verdade, é isso aí. Vem cá, olha a camisa do Vitor então. Olha a camisa, não pode não. A fase que a gente tá fugindo da aula dessa. Fala a voz do Tio Júlio também. Vai gritando. Pessoal, vamos lá. Olha, padrãozinho aí, enquadrados na minha, e batendo, beleza? Só pra você acaminhar a rede plural, vamos começar os dados com o salário, com o escritório. Olha, vou botar aqui a O exclusiva, certo? Beleza? Quando for 0 e 0, é 0, 0 e 1 é 1, 1 e 0 é 1, 1 e 1 é? 0. Beleza? Tá. NM. Fora essas variáveis, pessoal, o pessoal padronizou as variáveis. NM é o número de neurônomos. No caso, neurônomos A2, correto? Beleza? NA, número de amostra. Vamos pegar lá. Dados. Size. Dados. Beleza. Qual é a diferença? O cálculo, né? O cálculo vai mudar só o que a gente usa para o número 2? Não. Isso precisa de duas regras. Ah, é verdade. Dois regras. É... O número de amostra, né? NA. Número de entradas. Size. Dados. 2 menos 2. Beleza? Então, vamos lá. WE, peso do neurônomo de entrada. O que vai ser? For. I vai de 1 até quanto? Lembrar que o I vai ser o quê? O número de entradas, não é isso? NA. E o J vai ser o número de cogumelos, correto? Vamos lá. É comum, né? Então, o E vai ser o quê? For. E o J? O pessoal está com saudade de dados, não é? Não. Não. Vai continuar. Depois eu vou explicar para vocês. A gente tem que calcular a cidade ideal para cada cogumelo que tiver. Beleza? Saída, certo? Beleza? Aqui aparece o For. 1,2 neurônomo, certo? Mais um do Bias, correto? Então, por isso aqui eu criei meus pesos aleatórios já, correto? WE, WS, beleza? E o que eu vou fazer agora? A propagação. Eu vou deixar a taxa que eu vou precisar aqui dentro já, não. 0,6 para 2,5. Então, vamos lá. A M e a O, eu vou começar primeiro, certo? Vou começar com 1. Então, meu X, o que vai ser? Meus dados. A M e a linha. Do 1 até quem? Número de entrada, correto? Meu target. Então, os dados. A M. Número de entrada. Mais um. Pronto. X. Target, beleza? Pegando esses dois aqui, esses três no caso, o X e o target. Beleza. Vamos começar então. O Y, o que vai ser o Y? O que vai ser o Y? X vezes quem? WE, correto? Bota aqui. X vezes WE. Se eu botar aqui agora, eu tenho dois números. Dois números, está vendo? Certo? Eu tenho que fazer aqui, são dois números, então eu pego 4, e vai de 1 até 1,9. Y vai passar pela função de ativação, certo? Que é 1 dividido pelo 1 mais exponential de menos YI. Então, se eu colocar aqui, DISP Y. Vou colocar aqui também. Um, dois, três. Pronto. Aqui é antes de passar pela função de ativação, que aqui é depois que passou pela função de ativação. Y1, Y1, Y2, Y2. Beleza? Mais vontade? Vou apagar aqui. Bom, feito isso, o que eu vou fazer agora? O que eu já posso fazer para adiantar a minha vida? Eu já posso fazer meu Y elevado aqui, certo? Nessa função de ativação que você ensinou na aula passada, não é? Não, é agora. Não fiz aqui, fiz a elevada dela agora, a logística. E eu vou fazer aqui a mesma coisa. Vou pegar esse cara aqui. Aqui vai ser YD, correto? Qual é a derivada dele? YI que multiplica 1 menos o quê? YI. Fazer aqui o quê? Vou fazer a derivada do processo. Y, Y derivada. Certo? Vou só corrigir aqui, como você divulgou. Y derivada, só para ficar no formato de linha para mim aqui. Y, Y derivada. Beleza? Fiz a derivada dele aqui. O que eu vou fazer agora? Vou fazer o índice de saída. O que é o índice de saída? Você vê o quê? Menos 1, correto? E Y? Multiplicado por quem? Quando eu faço isso aqui, eu coloco menos 1 na frente. Está vendo? Certo? Multiplica quem? WS. Está aqui a saída do meu nome. Deu quanto? 0,28. Eu tenho que converter isso pela função de ativação ainda. Uma saída só, para conjugar a função de direta. WS.
aqui eu vou achar derivada dele, então vai ficar ys derivada eu fiz errado aqui, não sei, o que é isso? a gente pagou errado aqui, igual a ys derivada que multiplica 1 menos ys derivada já tem tudo o que eu preciso aqui para fazer o processo de aprendizagem a taxa de aprendizagem multiplicada por erro é o tamanho de menos do que saiu no ys o que é d0? vai ser o d multiplicado por h e i então vamos pensar uma forma legal aqui, meu we, meu h e hs são pequenos, não é isso? o que eu vou fazer aqui na brincadeira, para ficar mais dinâmico no processo? eu vou querer que eu faça a multiplicação do ws, certo? eu vou pegar ponta e coluna, vou colocar assim, vai ser todas as linhas do 2 até size, ws, ws1, beleza? e todas as linhas, vou colocar, o d0 aqui, e aqui é meu ws, eu expliquei pelo erro já, beleza? eu tenho que pegar esse d0 aqui, e fazer o ajuste dele aqui, 0 igual a d0 linha, beleza? vou tirar isso aqui só para mostrar para vocês, ws e d0, está vendo esses valores aqui? eu separei a primeira linha, correto? o que eu fiz? eu falei para ele pegar da segunda linha até o final do vetor, certo? e todas as colunas que eu tiver lá, beleza? quando você fala o ws, você está falando o que para ele? aqui é o seguinte, quando eu fiz aqui o d0, o d0 deu assim, só que eu vou multiplicar em linha, então eu preciso transformar isso com o vetor, é a transposta da matriz, certo? ele pegou esse cara aqui, jogou para cá, vai transposta, só isso, beleza? tem tudo pronto agora, vamos brincar aqui, o wsd vai ser o quê? a taxa de aprendizagem, que multiplica quem? primeiro de boa, não é? d, não é isso? multiplica quem? a derivada, ysd, que multiplica quem? os pesos, correto? o que são os pesos? as entradas, qual vai ser minha entrada aqui? a entrada minha não são meus ys, pessoal, não são meus ys? então eu vou colocar ele aqui, menos um e y, correto? e o wsd deu o quê? vai ajustar os três pesos neurais, e o wsd vai ser n, que multiplica quem? eu vou colocar meu d0, aqui é ponto vezes, se não me engano, y derivada, vou dar uma vez aqui só, então o wsd deu o quê? deu dois números, certinho? só que isso vai ter que ser multiplicado pelo quê? multiplicado pelas entradas, que são quais as minhas entradas? é o próprio x, correto? vou colocar aqui, x' multiplicado, wsd, está vendo? pessoal, o florisval não vai corrigir os pesos neurais, não vai corrigir nem o p, nem o c, nem o e, nem o f, está vendo? vai corrigir só os de cima, por quê, florisval? porque as duas primeiras entradas valem quanto? zero, se é zero, elas não tiveram participação no resultado da saída do neurônio, então por isso ele desconsidera, não tem participação alguma, aí acabou, eu venho aqui agora, eu faço o quê? for am de 1 até o número de amostras, end, vou fazer agora o operador nabla, estou brincando, época, vai ser igual a 1 até, piada de gente triste, não funciona com nós não, vai ter que explicar a piada, quer abrir uma atualização, ctrl a, ctrl i, o velho fica feliz, ficou feio, ficou ruim né, ficou agilentado e ficou ruim, beleza, vamos ver o que está acontecendo aqui, vamos aqui em cima criar, vamos ver se vai aprender primeiro, vou dar o disp aqui, disp ys, vamos ver o que vai fazer, é tão rápido assim, não tem graça, am, e vamos fazer aqui, we vai ser o quê? we mais wed, e ws vai ser igual a, não estou me ajudando, é foda, vamos ver se vai treinar, beleza, 0, 1, 1 e 0, está vendo, 0, 1, 1 e 0, 0, 1, 1 e 0, está ok? então ele vai pegar, vou fazer uma coisa para vocês verem aqui, deixa eu fazer o, grafo, grafo, grafo, tu dá o grafo que é mais fácil, ótimo, mas a intenção dele é, é colocar tipo assim, qualquer valor que eu aplicar ali, ele vai multiplicar, só que não pode ser maior que 1 esse valor, não, tem que fazer assim, mas eu acho que o chance de entrar é menor, você faz a escala, então vamos supor que é 0,8, ele vai multiplicar por, não sei na verdade, perdeu vai ser assim, plot, de 1 a 4, acho que é 4, y plot, de 1 a 4, de 1 a 4, é 0,1 e 0, olha pessoal, olha o que vai acontecer, vamos ver se vai dar certo, olha o Leonel aprendendo, o verde vai ficar, o verde é o que ele quer, e o azul é o que está treinando, então a cada ciclo, ele vai ajustando, esse é o objetivo dele, é o legal desse neurônio, vamos focar aqui, 2 neurônios, 10 neurônios, pela situação dele, agora tem 10 neurônios, é mais rápido, como estou usando a interface gráfica, fica carroça, então o que é a vantagem disso, Flavio Osvaldo, como é que eu vou usar uma rede neuronal, me explica, o que eu faço, vamos supor que eu tenho esses valores, não posso encontrar coisa, vamos supor que aqui vai ser, 0, olha, se eu mandar rodar, o neurônio tem que ser capaz, tem que mudar, o primeiro aqui é 0,83, ele tem que chegar no 0,4324, o outro tem que chegar no 0,001, está subindo aqui, tem que ajustar no formato que você moldou, vamos supor pessoal, que você foi contratado, para fazer uma modinha hoje, para a pessoa trabalhar, a pessoa aperta várias coisas lá, e dá o resultado final para a pessoa, então o que o cara faz normalmente, ele coloca vários valores lá, que vão entrar no processo de IA, que vai fazer o que, o conhecimento do cara, do psicólogo, se a pessoa marcar que gosta de bolo, e o bolo tem que ser de cobertura, bolo gelado, o cara vai falar, esse cara é um psicopata, então você vai evoluir, conforme você quer o resultado, ele vai achar um padrão, é o que ele está fazendo, para essas entradas, ele determinou um padrão, para estar sendo executado, vamos pensar mais longe, vamos falar, que eu vou fazer um robô, de fazer caixinha, está na moda? é muito bom que ela compre, a ação é lindíssima, você vai adorar, vamos falar, tem o sensor direito, e o sensor esquerdo, tem a cadela aqui, tem o sensor direito, o sensor esquerdo, e a saída, vamos falar o seguinte, minha rede neural vai de 0 a 1, vamos falar que aqui é 0 grau, aqui é 90, aqui é 180, é 0, meio, e 1, vou dizer minha rede neural, meio vai tocar em a reta, 1 vai rodar em 180, e vai, vamos fazer uma coisa, se não tiver sinal, em nenhum dos dois, qual é a saída do carrinho, não tem nada aqui na frente, meio, se tiver aqui, sinal de 1, tem sinal no lado direito, tem que mandar para o esquerdo, esquerda tem que mandar para cá, depois tem sinal, no lado esquerdo, tem que mandar para a direita, 1, tem sinal nos dois, o que eu vou fazer, é a opção sua, de virar para a direita ou para a esquerda, ou para cá, vou criar outra lógica aqui, vou botar aqui, sei lá, vou botar para a direita também, se tiver os dois, então eu venho aqui, eu monto o robôzinho lá, aquela porcaria do arduinho, monto o robôzinho, vou lá dentro e falo para ele, quando for 0 e 0 vai ser 0.5, quando for 0 e 1, aqui embaixo, vai ser 1, quando for 1 e 0 vai ser, 1 e 0 vai ser 0, e 1 e 1 vai ser, 1, deixa eu tirar isso daqui, dá para fazer isso aqui, deixa eu tentar arrumar aqui, aqui, esse cara aqui, é dados, todas as linhas, da coluna 4, da 4ª coluna, vamos tirar esse erro, que está me enchendo a paciência também, me dá um end-off aqui, vai, vou digitar, deixa eu ir para cá, vai, beleza, vamos dar rodada, deu pau, faltou alguma coisa aqui, a foto fechada, olha lá, o que está acontecendo aí, ele está aprendendo, que quando ele tiver isso aqui de sinal, é como que vai responder, mas se ele tem que entrar 1, entrar 0,5 aqui, com o padrão que você ensinou, no caso dessa rede de neurônios, tem 10 neurônios, ele vai se safar, pelo que você ensinou, então essa é a capacidade de generalização de um IA, porque é que a generaliza, porque essa que eu terminei 4 pontos, e o resto ela se vira, quem percebeu com o próximo, ele pode chegar na parede e se virar, pode fazer, mas e quando faz, que tem aquele sensor para não cair na escada, tem um sensor embaixo também? não, não serve, não, é que você calculava alguma distância, não, não, não, subiu, beleza, então pessoal, é a forma que a gente trabalha, o pessoal que trabalha com sistemas, tem várias aplicações, não é uma não, é várias, esse aqui, esse aqui, é o app, vocês já viram aqueles gráficos, o braço meio de ônibus, pessoal voltado, é a mesma coisa, o que é que faz, não é coisa do outro mundo, o que é que faz, você bota um dispositivo, você coloca na salgueira, e manda o cara falar assim, fecha a mão, fecha a mão, o cara lá imaginado é fechado, ele escolhe o curso de fechar a mão, levanta o dedão, vocês sabem que o pessoal que é voltado, sente a mão, dá conselho na mão, levanta o dedão, ele levantou o dedão, abre a mão, grava o ombro, para cada movimento, ele vai gravando o ombro, eles pegam vários músculos, e o músculo não vai atrofiar? não vai meter nenhum, só usa o peito, e o peito vai continuar, mas ele não vai atrofiar, conforme ele for envelhecendo, o que acontece? depois que tem tudo isso, o que vai acontecer? ele vai pegar a barragem, gravou a barragem, colocou no braço, fecha a mão, tem que fechar, o sistema vai ter que pegar aquela atenção, não vai ser a mesma, o sistema não é uma porcaria, o nosso sistema nem sempre é tudo igual, ele vai levantar, lembrando que é para fechar a mão, parece, vai fechar a mão, é a mesma ideia, só que é uma rede um pouco diferente dessa do braço, porque ela tem várias entradas, e várias saídas, porque é uma saída para cada motor, cada motor vai falar um ângulo, porque vai ter que colocar a mão, entendido? então o que vocês fazem agora? vocês brincam um pouco? então, fazer o Neuralink da vida, para quando o negro vai controlar essa mão, claro, mas acho que seria mais preciso, acho que o Neuralink não ia funcionar, ele levantou na segunda pessoa, acho que levantou, você não acha, por exemplo, que seria mais preciso o Neuralink para controlar a mão dessa? mas eu duro, o problema dessas coisas, pessoal, está lá dentro de Arquivos Junior, IAMC, salvei lá mesmo, o problema de você fazer uma metodologia invasiva, até se conseguir fazer, já apanhou muito, porque é tanta burocracia hoje, para fazer isso, o pessoal tenta fazer o máximo do externo, por exemplo, o teu colega começou a fazer mestrado comigo, e ele foi para essa parte vazia, ele gastou uns 5 euros no mestrado, eu gastei 2, eu fiz de forma noiva, você tem um país, mas sem lei, uma China na vida, e aí tem gente para a vontade, prisioneiro de guerra, os caras vão sentando sempre, os católicos lá, mas é, o católico está lá, para ele criar um monte de novo, beleza pessoal, quem quiser, acho que eu trouxe de novo, só mostrar uma coisa, o pessoal pediu um SOS, tem um livro que é muito bom, tem um livro que chama redes neurais, redes neurais artificiais para engenharia e ciências aplicadas, esse livro foi do meu professor, fiz uma matéria lá na UFSCar, esse livro aqui é muito bom, quem quiser, acho que tem que procurar, comprei esse aqui agora, outra versão, esse livro aqui é muito bom, esse livro é muito bom, é o mesmo autor? é o mesmo autor, é melhor pegar o seu mais novo? pode ser também, esse aí não é o aluno do cara que te deu mestrado? não é esse de baixo ainda? esse aqui, esse cara aqui, quem conhece o Gilberto aí? Gilberto, ele foi aluno do Gilberto, ele foi aluno do Gilberto, outro livro, tem que anotar esse aqui, pegar outro aqui, tem um ranking, esse aqui, muito bom, difícil, esse aqui é o mais novo saindo, espera aí, deixa eu tirar uma foto da capa, esse cara aqui, é muito técnico, é muito avançado isso aí, você chama a mãe, não é possível? não, não dá, é muito técnico, muito técnico isso aí, quantos anos de vida você gastou? anos de vida? eu gastei? aprendei isso aí, quanto tempo você gastou sozinho? quando eu vi a primeira rede neural em 1998, foi na aula do Virgílio, ele apresentou o primeiro perceptor pra mim, na aula do Virgílio, fiz engenharia de computação, daí eu, desde 1999, mais ou menos assim, a 2000, eu ingressei nessa área, conseguiu contabilizar? você fez elétrica? uns 20 anos aí, ou mais, você fez elétrica? mas como é que foi o seu 250 desse jeito e você falou, você apaixonou? você deu o seu caminho? se a gente entende assim como você entende, não fala igual realmente o professor Gilberto Galvão, como o Gilberto Galvão, fala igual o Gilberto fala, é melhor que sexo, não, hoje em dia, pessoal, é o seguinte, a parte de ensino, o Brasil mudou muito, quando eu fiz colegial, lá na classe, nem prestava atenção, tudo acontecia assim, a gente tinha um Raik, e você nem sabe o que é isso, era língua de cálculos, você tem ideia, no terceiro colegial, eu aprendia derivada e integral, limite, eu fui estudar na faculdade mesmo, cálculo, no cálculo 4, eu não tinha visto, no cálculo 1, 2 e 3 eu tinha visto no colegial, então, você tem Zé Ferreira, não é? era diferente assim, um jeito da coisa, hoje em dia, pessoa que chega na faculdade, custou ver uma matriz, porque o resto, você esquece, é como cai de casa, para mim é Deus, indique esses outros, que você fez para a gente, que você falou, Domino 20, você está louco? Domino 20 é pior que isso aqui, é pior, é pior, tem muito ouvido, não, mas isso era física, não, mas isso era física, não era derivada assim, até a internet atravou, você tem imagem básica, esse aqui, não dá, ele não tem dinheiro para comprar, não, mas era básico, é pior, não, mas isso aí, já é cálculo, é fudido, é cálculo fudido, e como é que começa no pré cálculo, no pré pré cálculo, quem quiser estudar, vou encerrar já, quem quiser estudar, aprofundar, depois tem os sistemas, o professor fala do mesmo programa, mas não mexe com isso, quem for, pessoal, pessoal pesquisado, programador top, top mesmo, mexe com isso, entra aqui no México, conhece, é uma diferença brutal, o que dá para você fazer, correr atrás, estuda, vou pegar um livro, passo para vocês, aplique cálculo numérico, tem engenharia aqui, só cálculo numérico, só cálculo numérico, e vocês vão ver o resto, porque o cálculo numérico, é um cálculo de computador, é um cálculo computacional, não é cálculo de fazer pontinha não, é cálculo computacional, você vai aprender a fazer o que, derivado num computador, integral, sempre pensar que você faz, você faz, tudo num cálculo, está liberado, beleza, eu estou perdendo o equilíbrio educacional, é tão caro no Brasil, os membros de história, tem parada agora no profissional, tem uma chamada aqui, ou o primeiro lá, eles sabem que...