Sabe quando você tem um personagem principal, e fica com um curseiro, uma fatia naquele personagem, esse personagem movimenta, e esse cara vai atrair ele com um raio? Essa rede neuronal é isso aqui. Quem viu isso aqui pensou que era uma rede, né? Mas ela é o pet ou o cara? Ela é o pet. O cara é o que você tem que parar. Bom, vamos lá pessoal. O que que acontece com essa rede? Então, como ela usa uma aproximação, a função de aprendizagem dela vai ser o que? W igual a W mais a taxa, X que é o personagem, menos a posição da fadinha. O que foi? É o W que foi para o W, certo? É só isso aqui. Não tem derivado, não tem nada, nada. É só isso aqui. Essa equação é usada em jogos digitais. Essa equação o que ela faz? Esse W vai perseguir o X, a mesma coisa aqui, a fadinha, o que seja, vai perseguir o personagem principal. O algoritmo é o mesmo. Se pegar os jogos lá, faz o movimento, acompanha, e pegar esse cara aqui, é a mesma coisa, a mesma função. Só que tem um malucão que viu isso aí e falou, olha, dá para fazer uma rede neuronal. Entendeu? Mas o que que acontece? Como funciona essa rede? Ela só tem camada de entrada intermediária. É assim, olha. Ela tem saída? Não. Ela tem vaias? Não. Ela só vai ter X, não tem o menos um e deu mais um. Não tem. E não tem saída. Tem função de ativação? Não. Tem nada. Não tem função de ativação. Mas é assim, para que que ela serve? Essa aqui é chamada também de redes auto-organizantes, de cron. O que que essa rede faz? Vou contar um exemplo que as meninas da engenharia de computação, talvez fizeram o DCC delas em cima disso. O que que elas tinham lá? Uma loja de música que julgaram, eu não vou falar o nome da tela de música, e ela tinha lá 10 mil dados. 10 mil ex-alunos, alunos desmilados. Onde que tinha lá? O nome, o sexo, a idade, o endereço, o ser bom pagador ou mau pagador, tem mais, o horário da aula, a hora da aula e o instrumento musical. Tinha lá mais umas 10, 15, é cada indivíduo 10, 15 variâncias ali para a pessoa fazer, correto? E o que que é o objetivo desse DCC das meninas? Elas vão fazer o que? Pegar essas 10 mil informações que eu tenho, 10 mil usuários, e montar um conjunto de 5 clusters. O que que esses clusters? São essas redes, elas fazem o que? Elas fazem a clusteringização dos dados. É como se eu tivesse vários dados assim, quadrado, triângulo, bolinho, ou misturado. Certo? O que que a gente precisa fazer? É separar o que que é igual, o que que é próximo. Ela vai separando. Eu estou falando de auto-organizantes, elas vão se separando, correto? E o que que as meninas chegaram lá depois? Para mim, é tudo. A gente tem lá os 5 clusters, essa rede, para vocês estarem mais localizados, ela é usada aonde mais? Na indústria 4.0? Mineração de dados. Uma rede que minera dados. Faz a mineração também. Está ok? Então a gente teve lá os clusters, e o que que foi legal disso aqui? Você pegava o cluster e falava assim, nossa, aqui 90% está fora, e 10% está na aula. O que que esse cluster estava me falando? Daqueles 10% aqui, tem toda a característica de sair. E sair com o custo. Então quando a empresa começou a fazer com esse pessoal, tem que dar uma promoção, tem que fazer alguma coisa, baixar preço, fazer alguma coisa ali, para segurar aqui toda a característica de sair. Como é que você descobriu isso? Porque a rede separou para mim. A gente vai pegar 10 mil dados, vai dar para os 10 mil dados, o que que eu vou fazer aqui dali? Não sei, é dado bruto, é um big data, um big data. E ela, o que que é isso? Depois dele cluster, lá estava assim, 20% fora, e 80% dentro da aula, aqui do lado. Aí o que que foi legal? Que a empresa pegou esses 20%, ligou, porque ele tinha toda a característica de voltar a assistir aula, e recuperou 15%, esse total 15%, quer dizer, foi só 5, foi meio dito. Ele tinha toda a característica de a gente pegar esse pessoal de volta. Entendeu? Porque eles tinham os dados, olha que legal, eles tinham todos os dados, mas não conseguiam instalar a informação deles. E essa rede não é uma rede difícil, não é uma rede difícil, e ela só faz o que? A organização desses dados, ele vai falar para mim assim, Flores Hall, mas ele vai me ver os caras aqui que não tem nada a ver um com o outro, mas para a rede é parecido. Às vezes a gente não enxerga isso, mas a rede, o padrão que ela encontrou, ela já pensou a pertença aqui de cluster. A gente não tenta, a gente tenta separar, mas não tem. Por exemplo, do fora, o que que é fora? Sai do concurso. Então isso é o que acontece, essa é a característica, que a gente foi descobrindo que o público-alvo de pessoal lá era o que? Eram mulheres, de vinte a quarenta anos, que moravam até cinco quilômetros do período do final da tarde, da manhã, e começo da tarde. Era o público-alvo que eles tinham. Acho que depois de outubro eram só homens, e de manhã crianças, meninas. O que que eles fizeram? Foram no Facebook, pagou a propaganda, circulou aí em volta, e outros. Acabou. Pronto, é isso. Não. Depois você vai pegar, o que que você vai fazer? A mineração, você pode pegar, você já estudou BI? É fora BI não, BI só. E fora a área de computação, estuda, quem quiser ganhar um pouquinho de dinheiro com isso. Você pega até figura, tem um livro, eu tenho ele, comprei, muito bom. O que que acontece? Toda figura que você pega tá lá, abrindo dente, trabalhando com o dado, ajustando, minerando, e no final tá um cara com uma lupa. Já viu isso aí? Essa imagem? Eu vou procurar aqui. Essa lupa tá falando o que? Quem vai depois fazer essa análise aqui, essa análise, cientista de dados, é o ser humano, o pessoal, o que que a gente fez? Perdeu tudo, a saída de risco, e colocou em porcentagem. Tantos porcento tá matriculado, tantos não. Por que? Você não vai ter aquele comum. Entendeu? Quem faz esse ajuste final, o ser humano. Preciso falar pra vocês, a minha época não vai ter emprego? Vai. O professor falou que não vai, vai, vai, tá? Vai mandar o dinheiro pra rua. Vai gerar muitos empregos também. Igual eu fiz, eu fiz um negócio com a minha empresa lá agora, com as imagens do meu site lá agora, fiz tudo aí assim, ó, e pronto. Tá lindo assim, ó. Design me enrotou. Assim é a vida. Eu só que apareço, eu sou o cientista, apareço como o analista de dados, aí quem vai fazer a análise de dados? Aí vai pegar aquele vaso depois, minerar e desblogar. Se o cara errar, ferra. Tá? Beleza? Então vamos falar dessa rede aí. Só isso. Outra coisa, como é que ela funciona? Só explicar assim, abroço no óculos, como é que essa rede funciona? Sem jato d'água, certo? Aquele neurônio que tem a menor soma euclidiana, lembra disso, do cálculo? Distância euclidiana? A gente não tem cálculo. A gente tem cálculo do colegial. A gente não tem cálculo. O colegial é esse. A nossa grade lindinha. O colegial é diferente. O colegial do Japão é diferente. O colegial do Japão é diferente. Não. O que tem que ser o ciclo diâmetro? Esse aqui. O pessoal de particular. O pessoal de particular, viu? Quem estudou José Ferreira vai em 90 minutos. Fora isso, não tem mais. Você quer a posição x e y, não tem? A gente vai aqui de x1 e de x2. Y1 e Y2, não é isso? Eu quero achar essa distância. A gente vai achar essa distância. A gente chama de distância o quê? Euculidiana. Como é que faz isso? Aqui, x2 menos x1. Tanto faz. Elevado ao quadrado. Mais y2 menos y1. Elevado ao quadrado. E a? A enche isso. E essa é a distância euclidiana. Só isso. Tá? Aí você vai fazer o quê? Esse aqui tem 3. Essa distância aqui dá 3. Essa distância aqui dá 4. Vai dar o quê? 25, é isso? Então a distância euclidiana é 25. Aí pensa em quem? A distância euclidiana vai ser feita com todos esses caras aqui? Sim. Com todos os caras de entrada. Ele vai realizar o peso neural com esse cara, com esse cara, com esse cara e com esse cara. E o que dê menor, quer dizer, se dê menor, quer dizer que esse neurônio ele tá mais próximo da amostra. Lembra da fadinha? Ele vai estar mais próximo. Se ele tá mais próximo, ele é o campeão. Aí eu vou falar assim, ó, aquele neurônio que deu a menor distância euclidiana ele vai estar ativado. Eu vou ativar o quê? Eu estou ativado porque essa amostra pertence a mim. Só isso ele vai fazer. Na memória ele tá no caso mais perto de 0. Na memória de 0? Na outra era mais perto de 1. Isso. Aí o que acontece aqui ainda? Se esse cara ganhou, o que você vai fazer? Você vai aplicar isso aqui. Em todos os pesos daquele neurônio que ganhou. Por quê? Porque você pega o neurônio e vai aproximar ele mais daquela amostra. Aí lembra da fadinha? Ela vai dar mais pra frente um pouquinho, aproximar daquela região. Então esse cara trabalha assim, ó. Tem várias amostras aqui. E aqui tá os neurônios. Tem quatro aí, ó. Tem quatro neurônios aqui no universo. Se esse aqui é o mais perto aqui, não é? Se ele ganha, o que vai acontecer? O algoritmo vai empurrar esse cara mais pra cá, ó. Então eles vão se acomodando até onde? Até ele definir que, ó, esse pedaço aqui é meu, esse pedaço é meu, esse cara talvez ele apanhe demais e vai jogar pra fora, tá? Esse pedaço aqui é meu, eu vou escolher esse aqui, ó. E vai moldando. Ah, mas eu não consigo fazer isso. Não consegue não. Sabe o que é? Até duas dimensões, x e y, você faz. Aqui é x, y, z, gama e vai embora. Não vai fazer um gráfico pra escolher nada, não tem jeito não. Até três vai, né? Passou de três e rolou. A quarta dimensão, vem embora. Ok? Então, você vai usar esse aqui, que ele vai deslocando no meio com esse aqui, que é uma coisa em 3D. Ele vai mexer no 3D também, na posição que tá a amostra de 3D. Beleza? Então vamos fazer. Ah, pessoal, quem quiser, depois, dá um chameirinho hoje ou tal, quem quiser depois. Chameirinho? Tá vendo? Já tá vendo a destino na vida. Tá aumentando a chance de passar. Tá aumentando, né? O pessoal que é mais esperto. Então, vamos lá. Como é que é? É 3D? É PET? É 3D? Hã? Capturou vocês aí? Não, hein? Um a zero. Você tá com isso aqui, gente? Aqui, ó. Esse aqui que eu desenhei pra vocês, ó. Mineração de gás, tá vendo? Tá vendo que passa pelo dado bruto, faz a limpeza, interação, transformadora, mineração, a LVQ tá aqui, ó. Mineração, você vai levantar os padrões e fazer a análise com conhecimento da pessoa aqui, tá vendo? Geralmente a gente bota uma pessoa aqui analisando. Aqui, ó. Esse é do livro, ó. No final, pessoal, você não pode ficar olhando por ali e falar assim, ó, deu bem com esse lado aqui. Tá ok? Vamos lá, então. Cadê o Nossa Senhora? Ai, te levo a saudade de alguém que tá chorando. Então, vou deletar isso aqui. Beleza? Vamos lá. Ó, como é padrão aí, pessoal, sempre usar o CLEAR e o CLC, tá? A vontade, não. Vamos lá. O que eu preciso, primeiramente? Os dados, correto? Então, o dado, ó. Vou colocar aqui, um, bem simplesinho assim, ó. Só pra dar certo no final aqui, ó. A gente possui muito mais dados, tá, pessoal? Aqui é só quatro posições que tá onde. Então, beleza, ó. Tem meus dados gerados aqui? Já vão dar? É. Tem. Tem que ser quatro coluna e quatro linha. Tem que ser quadrada, nada disso. Tá vendo? Mas assim, ó. As linhas tem que ter a mesma quantidade toda, né? Beleza, então. Tá meus dados aqui. O que que eu vou fazer, primeiramente? Qual que você trata como neurônio? É a linha ou a coluna? Não, é agora. Isso aqui é dados. Mas eu trato coluna sendo neurônio e linha sendo quadrada. Você tem os seus dados, mas você não sabe. Isso é um alunamento. Desiste. Um alunamento. Há uns anos atrás? Esse aluno não sabe nenhum. Esse aluno, uma vez, que saiu gritando. Já voltou depois de dois anos. Portou, né? Portou. Depois que o pacotera viu, saiu gritando. Eu não sei se é verdade, se eu escolho. Não vai ser comigo, não, tá, gente? Não vai ser comigo, não. Vamos lá, ó. O que que eu vou fazer? Agora, em vez de ser número de neurônio, eu vou fazer número de NC, número de classes. Por quê? Esse neurônio, por causa do neurônio, vai ser uma classe, entendeu? Umas classes. Eu vou deixar aqui duas classes, ó. Número de entradas que eu tenho no meu processo. No caso, vai ser o número de colunas que eu tenho aqui, correto? Número de entradas vai ser igual ao tamanho dos dados colunas, ok? Qualquer coisa aqui você não vai pagar, não, tá, pessoal? Bonito, tá? Então, ó, tá aqui a quantidade de entradas que eu tenho, tá? Pessoal, cadê o BIAS? Colocava mais um aqui e tal, menos um? Não tem, tá? Vocês esquecem, tá? Esquece tudo. Ok? Por que você não estimulou essa primeiro? Porque a ordem cronológica é essa. Começou com o coerceco, o coerceco de camada e foi subindo. Tá? Eu nem pergunto, né? Então, vamos lá. Criei meus pesos. Então, só W, tá? Não tem W de entrada, W de saída, não. Só W, tá? Eu tenho meu W aqui, ó. Então, de fora vai ser o quê? Como o meu número de, como é que fala? Como o meu NC, então, do J, não é? Vai ser de 1 até número de classes, que é o número de neurônios. E vai de 1 até o quê? Número de entradas, correto? É o mesmo padrãozinho que eu aplico nos outros, ó. Não precisa fugir tanto, ó. Um range também, aleatório, ó. Gera. Agora, esse aqui são meus neurônios, certo? 2 neurônios com 4 entradas, certo? 4 entradas, 4 entradas. Beleza. O que que eu faço agora? Ó, eu vou definir a quantidade de amostras que faltou aqui, o número de amostras, aqui ó, N, A. O que que é o número de amostras? Size, dados, 1. Beleza. E pessoal, pras próximas aulas, eu vou estudar mais essa matriz, tá, que nós vamos fazer a rede Hopperfield. É um russo que fez, o negócio é russo. Tá? Hã? Vamos lá, então. É, criei, peguei a quantidade de amostras, eu vou criar aqui um AN, tá, que é minha amostra, que eu dou 2x, tá, só pra mim fazer aqui, depois eu fecho lá, ok? Então eu faço o quê? O que que vai ser meu X? Meu X vai ser dados, N e todas as suas colunas, correto? Eu faço isso, ó. Esse aqui é o Coringuinha, certo? Todos, significa, eu posso ter isso. Então ó, X, ó, eu peguei a primeira aqui, correto? Certo? Vou pra lá, vou ter meu X. O que que eu tenho que fazer agora, Fransvaldo? Eu tenho que calcular a distância euclidiana de cada neurônio que eu tenho. Cada neurônio que eu tenho, eu tenho que calcular a distância euclidiana. Então, ó, se eu vou ter que correr os neurônios, então eu vou fazer aqui, ó, I e J, né, que é o neurônio, vai de 1 até o quê? Número de classe, certo? Depois, eu tenho que parrer as linhas, então FOR vai ser o quê? E também de 1, que é o número de entradas. E vou criar aqui, agora eu tenho que começar a brincar aqui, né, ó, colocar aqui uma soma igual a 0, certo? Eu vou acumular aqui dentro, correto? Ó, soma vai ser igual a soma mais o quê? Mais a, cadê, W, só que W vai ser, Fransvaldo, ó, é o I e o J, correto? Certo? E aqui vai ser o X, né, X o quê? I, que é a entrada, correto? Menos. Eu tô fazendo, pessoal, a distância euclidiana, tá, ó, só que eu vou somando todas separadamente, tá vendo, ó? A distância do X, o W vai perseguir esse X aqui, certo? Eu vou somar tudo. Quando terminar de somar, o que eu vou fazer? Soma vai ser igual a raiz de soma depois de tirar a raiz depois da euclidiana, aqui, pessoal, o que que eu fiz, ó, aqui eu tenho quatro entradas, vai vir somando aqui, tá, ó, mais ao quadrado, mais ao quadrado, até o final, eu vim somando isso, depois de tirar a raiz, entendeu? Eu vim somando todo mundo pra eu tirar a raiz no final. Isso. Aí eu vou fazer o quê? Guardar o valor. Vou criar aqui um carinha aqui, ó, chamado valor, sei lá, valor ou ativação, ativacão, ativa, ó, vai, por que que ele calcula, tipo, essa quarta dimensão? Por que que seria essa quarta dimensão que ele calcula? Ele vai analisar a chave inteira do vetor. Não é a quarta não, vai lá, vai do que tiver. Mas o que que dá isso? A gente não sabe nem compreender o que que seria essas dimensões. Não. Nem a quarta a gente consegue? Não. Mas isso dá o resultado? Não. Eu sei que é por isso que se usa essa rede pra ela enxergar uma situação que a gente não vai enxergar, entendeu? Por isso que usa ela. Cada neurônio tem uma dimensão? Cada neurônio tem duas dimensões. É. Cada entrada tem uma dimensão. A entrada dele, as entradas. Se eu tiver duas entradas, dois dele, três, três, quatro, não vai me enganar, três entradas. Entendi. Então, beleza, ó, faz a soma. Aí aqui, ó, quando ele sair do processo final aqui, ó, fala o que? Que meu, que a minha ativa, que a ativação, e, né, porque a, e, não, e, não, escuta, j, né, então, conjunto, vai receber soma, correto? Vou dar uma vez aqui, ó, vou ver se vai dar erro. Não deu erro? Ativa. Ó, tá vendo que ele fez com o primeiro neurônio e fez com o segundo. Quem que foi o campeão? O segundo neurônio. O valor menor. Certo? Ó, pra essa entrada aqui, ó, vamos pegar aqui os pesos, ó, W, pra essa entrada aqui, esse aqui tá mais perto da resposta. Se você for olhar, tá, tá vendo, ó, é 1, 0.3, 1, 0.92, 0.21, 0.21, beleza, tá bem junto. Essa outra de cá, ó, tinha que ser 0,0, 0.2, 0.2. Aqui tinha que ser 0, tá quase 1, né, ó. E aqui tem que ser 0, 0.65, tá vendo? Na verdade agora não entendi nada. Ó, se você fazer isto menos, o que foi feito? Isto menos isto elevado ao quadrado. Depois, isto mais menos isto elevado ao quadrado. Ao quadrado, menos ao quadrado. Isso. Aí o resultado disso, tirando a raiz, deu isso aqui. E foi feito com esse. Mas só de olhar aqui, pessoal, já dá pra ver que esse é o campeão. Porque, ó, esse tá mais próximo de 1 do que esse. Esse tá mais próximo de 1, ó, o segundo. O segundo tem que ser 1, né, ó. Do que esse. Esse tá mais próximo de 0 do que esse aqui. E esse tá mais próximo de 0 do que esse. Esse é ganhar mesmo, esse segundo aqui. Esse é ganhar. Beleza? A gente tá olhando só a primeira linha ali, 1, 1, 0, 0. É, o 1 só primeiro, ó. Eu traguei em 1, ó. Eu traguei só a primeira linha. Não deixei eu rodar todas. Eu só tô analisando a primeira. Ah, entendi. Realmente. Quando é pequena, poucas variáveis, você consegue ver quem vai ganhar logo. Se você quiser gravar a minha, tá mais próximo. E aí, no caso, nessa primeira linha, são os primeiros dados que estão entrando no primeiro leoloto. Todos. Tá entrando todas as linhas dele? Todas as minhas. Uma vez? Uma vez. Ele analisa na somatória quem possui a menor distância eclidiana deles. Ah, porque então, no caso, são essas 4 linhas que estão entrando neles, são pra ele ter, pra ele treinar. É, tá treinando. Entendi. Pessoal, ó, só pra ficar uma coisa... Deixa eu montar uma coisinha aqui, só pra vocês entenderem o que esse neurônomo faz. É... Se você pegar aqui, por exemplo, ó, 4 e vai de 1 até, sei lá, 10 mil. Vou fazer aqui um x igual a 10 vezes o range. O range, só isso. E eu vou fazer aqui a aprendizagem dele, ó. É W igual a W mais... Eu vou colocar W inicial aqui, né? W inicial igual a 0. Igual a 0.5 vezes o x menos o W, certo, ó? Tá no quadro, né? A formulinha aqui? É a mesma, tá vendo? Esse m, ele é o coeficiente de aprendizagem? Isso. E esse x aqui? Ah, esse aí é 0.5. Esse aí é 0.5. Esse mais baixo ainda aí. Cada rede é um processo. Eu vou colocar aqui, ó, plot é... Ah, eu tenho que fazer um x e um y aqui, né? Peraí. Desculpa aí. Vou fazer um x e um y pra fazer um gráfico pra vocês verem, né? Só não tem graça, ó. Certo? E aqui eu vou fazer o Wx, ó. E o Wy. Eu vou ter só duas dimensões. Só duas. Eu vou fazer com duas, aí dá pra você enxergar aqui a brincadeira, entendeu? Eu vou colocar aqui... No SciLab não tem como colocar, tipo, três dimensões pra ele renderizar? Aqui dá. E aqui vai ficar Wx, né? E Wy, ó. Vou colocar aqui um slip. Ó. É, basicamente. Teste aqui mesmo, não sei nem o que é isso. Mas o que eu fiz aqui? Wx. Ah, é. Tem que declarar eles, né? Senão dá B.O., né? Se eu for... Cadê? Ah, isso aí é ruim isso aqui? É a quarta dimensão. Não. Vou fazer uma coisa aqui, ó. Esse bicho é burro mesmo. É Wx. Acho que é O que dá pra fazer. Deixa eu ver. Aqui tá vendo o x e o O? O x tá lá, ó. Esse aqui é o O, tá vendo? O O, o que ele vai fazer? Onde que o x for, ele vai tentar ir atrás do O. Só que eu exagerei demais aqui, né? Deixa eu fazer uma coisa devagar aqui, pera aí. Empolguei. Vou fazer assim, ó. Vamos fazer... Vou fazer uma variação bem pequenininha. 0.1, ó. E vamos fazer e somar com ele mesmo, ó. Mais x. Mais y. x, y. Vai ser mais fácil fazer assim, ó. Aí vocês vão conseguir B. Eu vou colocar também a posição inicial desse cara lá no 10, ó. Ó. Tá vendo o x aqui andando, ó? A fadinha atrás do... Tá vendo? Aquela voltando atrás, ó. Tá vendo? Onde que ele tá indo, ó? Ele tá indo atrás do x, ó. Esse neurônio aprende desse jeito, ó. Tá vendo? Ele tá indo atrás. É um míssil, ó. Onde que a entrada do neurônio vai, o peso dele vai atrás da entrada. Tá vendo? Tá acontecendo, ó. Mas o neurônio aí é o x ou é o y? O neurônio é a bolinha. O x é a entrada.
A gente faz isso mesmo, é a entrada. Quando a menina acha que ela está rindo, ele vai atrás dela. Está vendo? Esse negócio é aprendido desse jeito. É a mesma ideia do jogo que eu falei para vocês. O personagem vai andando e ele vai atrás
